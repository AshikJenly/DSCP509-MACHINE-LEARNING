{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23fbaef-26b0-4fa1-a2aa-fc2b05f9726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8df2f-63b7-4e39-a1d0-e25845489f4a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\\begin{align*}\n",
    "&\\text{Initialization:} \\\\\n",
    "&\\qquad \\text{For each layer } l \\in \\{1, 2, \\ldots, L\\}: \\\\\n",
    "&\\qquad \\qquad W^{[l]} \\sim \\mathcal{N}(0, \\sigma^2 I_{n^{[l]}, n^{[l-1]}}) \\\\\n",
    "&\\qquad \\qquad b^{[l]} \\sim \\mathcal{N}(0, \\sigma^2 I_{n^{[l]}}) \\\\\n",
    "&\\text{Forward Propagation:} \\\\\n",
    "&\\qquad \\text{For each layer } l \\in \\{1, 2, \\ldots, L\\}: \\\\\n",
    "&\\qquad \\qquad Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]} \\\\\n",
    "&\\qquad \\qquad A^{[l]} = g^{[l]}(Z^{[l]}) \\\\\n",
    "&\\text{Cost Calculation:} \\\\\n",
    "&\\qquad J = -\\frac{1}{m} \\sum_{i=1}^m \\left( y^{(i)} \\log(A^{[L] (i)}) + (1 - y^{(i)}) \\log(1 - A^{[L] (i)}) \\right) \\\\\n",
    "&\\text{Backpropagation:} \\\\\n",
    "&\\qquad \\text{For each training example } i \\in \\{1, 2, \\ldots, m\\}: \\\\\n",
    "&\\qquad \\qquad \\text{Output layer:} \\\\\n",
    "&\\qquad \\qquad \\qquad dZ^{[L] (i)} = A^{[L] (i)} - y^{(i)} \\\\\n",
    "&\\qquad \\qquad \\qquad dW^{[L]} = \\frac{1}{m} dZ^{[L] (i)} A^{[L-1] (i) T} \\\\\n",
    "&\\qquad \\qquad \\qquad db^{[L]} = \\frac{1}{m} \\sum_{i=1}^m dZ^{[L] (i)} \\\\\n",
    "&\\qquad \\qquad \\qquad dA^{[L-1]} = W^{[L] T} dZ^{[L]} \\\\\n",
    "&\\qquad \\qquad \\text{Hidden layers:} \\\\\n",
    "&\\qquad \\qquad \\qquad dZ^{[l] (i)} = dA^{[l] (i)} \\cdot g^{[l]'}(Z^{[l] (i)}) \\\\\n",
    "&\\qquad \\qquad \\qquad dW^{[l]} = \\frac{1}{m} dZ^{[l] (i)} A^{[l-1] (i) T} \\\\\n",
    "&\\qquad \\qquad \\qquad db^{[l]} = \\frac{1}{m} \\sum_{i=1}^m dZ^{[l] (i)} \\\\\n",
    "&\\qquad \\qquad \\qquad dA^{[l-1]} = W^{[l] T} dZ^{[l]} \\\\\n",
    "&\\text{Parameter Update:} \\\\\n",
    "&\\qquad \\text{For each layer } l \\in \\{1, 2, \\ldots, L\\}: \\\\\n",
    "&\\qquad \\qquad W^{[l]} = W^{[l]} - \\alpha dW^{[l]} \\\\\n",
    "&\\qquad \\qquad b^{[l]} = b^{[l]} - \\alpha db^{[l]}\n",
    "\\end{align*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636c17b5-049c-4c3c-8718-8cea683ba448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org, y_train, X_test_org, y_test = np.load('datas/Files/cat_train_x.npy'),np.load('datas/Files/cat_train_y.npy'),np.load('datas/Files/cat_test_x.npy'),np.load('datas/Files/cat_test_y.npy')\n",
    "train_x_flatten = X_train_org.reshape(X_train_org.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = X_test_org.reshape(X_test_org.shape[0], -1).T\n",
    "\n",
    "X_train = train_x_flatten/255.\n",
    "X_test = test_x_flatten/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8126245d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 209)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a867bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[158, 104,  83],\n",
       "         [161, 106,  85],\n",
       "         [162, 107,  84],\n",
       "         ...,\n",
       "         [170, 120, 100],\n",
       "         [167, 121, 103],\n",
       "         [172, 127, 109]],\n",
       "\n",
       "        [[158, 103,  82],\n",
       "         [160, 104,  82],\n",
       "         [162, 105,  83],\n",
       "         ...,\n",
       "         [169, 118,  99],\n",
       "         [164, 117,  98],\n",
       "         [168, 121, 104]],\n",
       "\n",
       "        [[158, 104,  82],\n",
       "         [161, 105,  82],\n",
       "         [162, 105,  83],\n",
       "         ...,\n",
       "         [173, 123, 102],\n",
       "         [169, 122, 104],\n",
       "         [168, 122, 104]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[102,  68,  52],\n",
       "         [ 44,  31,  23],\n",
       "         [ 28,  23,  20],\n",
       "         ...,\n",
       "         [163, 118, 102],\n",
       "         [163, 120, 103],\n",
       "         [166, 121, 105]],\n",
       "\n",
       "        [[ 99,  67,  51],\n",
       "         [ 38,  28,  22],\n",
       "         [ 30,  26,  23],\n",
       "         ...,\n",
       "         [161, 117, 100],\n",
       "         [164, 121, 104],\n",
       "         [168, 123, 106]],\n",
       "\n",
       "        [[127,  95,  72],\n",
       "         [ 39,  29,  22],\n",
       "         [ 30,  25,  22],\n",
       "         ...,\n",
       "         [165, 122, 105],\n",
       "         [169, 126, 109],\n",
       "         [173, 128, 110]]],\n",
       "\n",
       "\n",
       "       [[[115, 110, 111],\n",
       "         [137, 129, 129],\n",
       "         [155, 146, 145],\n",
       "         ...,\n",
       "         [159, 156, 157],\n",
       "         [141, 141, 145],\n",
       "         [121, 122, 127]],\n",
       "\n",
       "        [[123, 118, 120],\n",
       "         [143, 136, 136],\n",
       "         [159, 153, 150],\n",
       "         ...,\n",
       "         [167, 164, 165],\n",
       "         [151, 151, 154],\n",
       "         [130, 133, 137]],\n",
       "\n",
       "        [[135, 130, 130],\n",
       "         [150, 145, 141],\n",
       "         [164, 159, 153],\n",
       "         ...,\n",
       "         [173, 174, 172],\n",
       "         [160, 162, 162],\n",
       "         [141, 144, 148]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[197, 196, 205],\n",
       "         [208, 209, 214],\n",
       "         [215, 216, 220],\n",
       "         ...,\n",
       "         [222, 224, 229],\n",
       "         [205, 208, 215],\n",
       "         [185, 189, 197]],\n",
       "\n",
       "        [[190, 192, 199],\n",
       "         [203, 205, 210],\n",
       "         [213, 214, 218],\n",
       "         ...,\n",
       "         [217, 220, 225],\n",
       "         [198, 202, 209],\n",
       "         [178, 182, 191]],\n",
       "\n",
       "        [[183, 186, 193],\n",
       "         [197, 199, 205],\n",
       "         [208, 210, 214],\n",
       "         ...,\n",
       "         [212, 215, 220],\n",
       "         [192, 196, 203],\n",
       "         [171, 176, 186]]],\n",
       "\n",
       "\n",
       "       [[[255, 253, 254],\n",
       "         [255, 253, 254],\n",
       "         [255, 253, 254],\n",
       "         ...,\n",
       "         [197, 178, 118],\n",
       "         [195, 177, 116],\n",
       "         [192, 176, 115]],\n",
       "\n",
       "        [[255, 253, 254],\n",
       "         [255, 253, 254],\n",
       "         [255, 253, 254],\n",
       "         ...,\n",
       "         [197, 178, 120],\n",
       "         [195, 176, 118],\n",
       "         [193, 174, 118]],\n",
       "\n",
       "        [[255, 253, 254],\n",
       "         [255, 253, 254],\n",
       "         [255, 253, 254],\n",
       "         ...,\n",
       "         [197, 177, 121],\n",
       "         [194, 174, 121],\n",
       "         [190, 171, 122]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 94,  95,  97],\n",
       "         [102, 104, 108],\n",
       "         [115, 113, 115],\n",
       "         ...,\n",
       "         [ 68,  67,  91],\n",
       "         [ 71,  55,  80],\n",
       "         [ 64,  51,  82]],\n",
       "\n",
       "        [[ 68,  71,  69],\n",
       "         [ 75,  79,  80],\n",
       "         [ 82,  91,  91],\n",
       "         ...,\n",
       "         [122, 103, 109],\n",
       "         [114,  84,  99],\n",
       "         [ 97,  72, 100]],\n",
       "\n",
       "        [[ 67,  86,  89],\n",
       "         [ 62,  83,  90],\n",
       "         [ 47,  73,  82],\n",
       "         ...,\n",
       "         [147, 120, 125],\n",
       "         [142, 110, 118],\n",
       "         [133, 101, 121]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 41,  47,  84],\n",
       "         [ 72,  78, 112],\n",
       "         [103, 102, 124],\n",
       "         ...,\n",
       "         [125, 112, 119],\n",
       "         [107, 101, 117],\n",
       "         [ 76,  79, 109]],\n",
       "\n",
       "        [[ 93,  96, 119],\n",
       "         [112, 109, 124],\n",
       "         [130, 122, 136],\n",
       "         ...,\n",
       "         [141, 121, 118],\n",
       "         [130, 112, 114],\n",
       "         [122, 109, 117]],\n",
       "\n",
       "        [[119, 114, 123],\n",
       "         [133, 124, 128],\n",
       "         [164, 149, 145],\n",
       "         ...,\n",
       "         [187, 160, 135],\n",
       "         [157, 132, 120],\n",
       "         [136, 115, 109]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[233, 223, 207],\n",
       "         [235, 226, 218],\n",
       "         [242, 236, 235],\n",
       "         ...,\n",
       "         [164, 170, 196],\n",
       "         [189, 185, 196],\n",
       "         [190, 182, 188]],\n",
       "\n",
       "        [[247, 250, 248],\n",
       "         [236, 238, 232],\n",
       "         [219, 215, 219],\n",
       "         ...,\n",
       "         [118, 101, 117],\n",
       "         [153, 134, 154],\n",
       "         [174, 146, 156]],\n",
       "\n",
       "        [[253, 254, 254],\n",
       "         [246, 250, 249],\n",
       "         [226, 233, 234],\n",
       "         ...,\n",
       "         [154, 111,  93],\n",
       "         [176, 132, 104],\n",
       "         [183, 141, 116]]],\n",
       "\n",
       "\n",
       "       [[[ 18,  18,  16],\n",
       "         [ 35,  36,  31],\n",
       "         [ 54,  57,  52],\n",
       "         ...,\n",
       "         [138, 140, 118],\n",
       "         [139, 141, 124],\n",
       "         [130, 129, 114]],\n",
       "\n",
       "        [[ 21,  21,  18],\n",
       "         [ 44,  45,  39],\n",
       "         [ 68,  74,  66],\n",
       "         ...,\n",
       "         [128, 131, 109],\n",
       "         [116, 117,  98],\n",
       "         [ 95,  93,  76]],\n",
       "\n",
       "        [[ 30,  31,  26],\n",
       "         [ 54,  58,  52],\n",
       "         [ 99, 110, 104],\n",
       "         ...,\n",
       "         [127, 129, 108],\n",
       "         [113, 114,  94],\n",
       "         [ 99,  99,  82]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[178, 178, 163],\n",
       "         [161, 163, 146],\n",
       "         [170, 174, 163],\n",
       "         ...,\n",
       "         [112, 108,  85],\n",
       "         [149, 150, 131],\n",
       "         [180, 185, 172]],\n",
       "\n",
       "        [[182, 183, 167],\n",
       "         [172, 175, 162],\n",
       "         [170, 173, 162],\n",
       "         ...,\n",
       "         [ 88,  90,  77],\n",
       "         [122, 115,  89],\n",
       "         [157, 154, 131]],\n",
       "\n",
       "        [[188, 190, 179],\n",
       "         [173, 175, 163],\n",
       "         [160, 162, 146],\n",
       "         ...,\n",
       "         [ 48,  50,  44],\n",
       "         [103, 103,  89],\n",
       "         [144, 137, 108]]],\n",
       "\n",
       "\n",
       "       [[[133, 163,  75],\n",
       "         [ 98, 120,  44],\n",
       "         [108, 132,  47],\n",
       "         ...,\n",
       "         [ 96, 138,  97],\n",
       "         [ 96, 146, 109],\n",
       "         [ 81, 132, 101]],\n",
       "\n",
       "        [[ 79, 102,  39],\n",
       "         [ 83, 112,  33],\n",
       "         [ 76, 106,  26],\n",
       "         ...,\n",
       "         [ 99, 149,  76],\n",
       "         [ 71, 119,  62],\n",
       "         [ 58, 106,  72]],\n",
       "\n",
       "        [[ 35,  53,  27],\n",
       "         [ 54,  74,  46],\n",
       "         [ 35,  55,  17],\n",
       "         ...,\n",
       "         [110, 157, 122],\n",
       "         [ 72, 119,  89],\n",
       "         [ 81, 131, 108]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 76, 108,  79],\n",
       "         [ 70, 110,  83],\n",
       "         [ 70, 105,  84],\n",
       "         ...,\n",
       "         [ 25,  49,  21],\n",
       "         [ 26,  53,  24],\n",
       "         [ 27,  54,  28]],\n",
       "\n",
       "        [[109, 120,  97],\n",
       "         [ 86, 116,  86],\n",
       "         [ 71, 105,  79],\n",
       "         ...,\n",
       "         [ 17,  46,  20],\n",
       "         [ 23,  49,  28],\n",
       "         [ 19,  33,  18]],\n",
       "\n",
       "        [[ 97, 117, 100],\n",
       "         [ 70, 108,  75],\n",
       "         [ 75,  99,  69],\n",
       "         ...,\n",
       "         [  8,  33,  12],\n",
       "         [ 13,  35,  18],\n",
       "         [  5,  22,   5]]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338bbad8-2e58-4692-beed-1b851755b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_train_org[1])\n",
    "print(y_train[0][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951cd8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 209)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6903242b",
   "metadata": {},
   "source": [
    "# Partial changes needed to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3704a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, layer_dims, beta=0.9):\n",
    "        self.layer_dims = layer_dims\n",
    "        self.parameters = {}\n",
    "        self.cost = 0\n",
    "        self.number_of_layers = len(self.layer_dims) - 1\n",
    "        self.beta = beta\n",
    "        self.v = {} \n",
    "\n",
    "def __update_parameters(self, learning_rate, grads):\n",
    "        for l in range(1, self.number_of_layers):\n",
    "            # Update the velocity using momentum\n",
    "            self.v[\"dW\" + str(l + 1)] = self.beta * self.v.get(\"dW\" + str(l + 1), 0) + (1 - self.beta) * grads[\"dW\" + str(l + 1)]\n",
    "            self.v[\"db\" + str(l + 1)] = self.beta * self.v.get(\"db\" + str(l + 1), 0) + (1 - self.beta) * grads[\"db\" + str(l + 1)]\n",
    "\n",
    "            # Update parameters using momentum\n",
    "            self.parameters[\"W\" + str(l + 1)] = self.parameters[\"W\" + str(l + 1)] - learning_rate * self.v[\"dW\" + str(l + 1)]\n",
    "            self.parameters[\"b\" + str(l + 1)] = self.parameters[\"b\" + str(l + 1)] - learning_rate * self.v[\"db\" + str(l + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (other parts of the code)\n",
    "\n",
    "class BPNN:\n",
    "    # ... (previous methods and initialization)\n",
    "\n",
    "    def __cost(self, A_last_layer, y, lambd):\n",
    "        m = y.shape[1]\n",
    "        cross_entropy_cost = (-1 / m) * np.sum(np.multiply(y, np.log(A_last_layer)) + np.multiply(1 - y, np.log(1 - A_last_layer)))\n",
    "        \n",
    "        # Regularization term\n",
    "        L2_regularization_cost = 0\n",
    "        for l in range(1, self.number_of_layers + 1):\n",
    "            L2_regularization_cost += np.sum(np.square(self.parameters[\"W\" + str(l)]))\n",
    "        \n",
    "        cost = cross_entropy_cost + (lambd / (2 * m)) * L2_regularization_cost\n",
    "        self.cost = np.squeeze(cost)\n",
    "\n",
    "    def __backward_propagation(self, A_last_layer, y, caches, lambd):\n",
    "        grads = {}\n",
    "        L = self.number_of_layers\n",
    "        y = y.reshape(A_last_layer.shape)\n",
    "\n",
    "        dA_last_layer = - (np.divide(y, A_last_layer) - np.divide(1 - y, 1 - A_last_layer))\n",
    "        dA_prev, dW, db = self.linear_activation_backward(dA_last_layer, caches[L - 1], \"sigmoid\")\n",
    "        \n",
    "        # Add L2 regularization term to gradient\n",
    "        dW += (lambd / A_last_layer.shape[1]) * self.parameters[\"W\" + str(L)]\n",
    "\n",
    "        grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = dA_prev, dW, db\n",
    "\n",
    "        for l in reversed(range(L - 1)):\n",
    "            dA = dA_prev\n",
    "            dA_prev, dW, db = self.linear_activation_backward(dA, caches[l], \"relu\")\n",
    "            \n",
    "            # Add L2 regularization term to gradient\n",
    "            dW += (lambd / A_last_layer.shape[1]) * self.parameters[\"W\" + str(l + 1)]\n",
    "\n",
    "            grads[\"dA\" + str(l)] = dA_prev\n",
    "            grads[\"dW\" + str(l + 1)] = dW\n",
    "            grads[\"db\" + str(l + 1)] = db\n",
    "\n",
    "        grads[\"dA1\"] = grads['dA2']\n",
    "        del grads['dA2']\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.001, num_iter=1000, print_cost=False, lambd=0.0):\n",
    "        # ... (other parts of the code)\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            # ... (other parts of the code)\n",
    "\n",
    "            #backward propagation\n",
    "            grads = self.__backward_propagation(A_last_layer=last_layer_output,\n",
    "                                                y=y,\n",
    "                                                caches=caches,\n",
    "                                                lambd=lambd)\n",
    "\n",
    "            # ... (other parts of the code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b788b",
   "metadata": {},
   "source": [
    "# Plain Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d416bb2-9c21-4219-885f-d0ec9efc279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN:\n",
    "    def __init__(self,layer_dims):\n",
    "        self.layer_dims = layer_dims\n",
    "        self.parameters = {}\n",
    "        self.cost = 0\n",
    "        self.number_of_layers = len(self.layer_dims) - 1\n",
    "\n",
    "\n",
    "    def __initialize_paramters(self):\n",
    "        np.random.seed(1)\n",
    "        for l in range(1,self.number_of_layers + 1):\n",
    "            self.parameters[\"W\"+str(l)] = np.random.randn(self.layer_dims[l],self.layer_dims[l-1]) * 0.01\n",
    "            self.parameters[\"b\"+str(l)] = np.zeros(shape=(self.layer_dims[l],1))\n",
    "            \n",
    "    def __forward_propogation(self,X):\n",
    "\n",
    "        def relu(x):\n",
    "            return np.maximum(0,x)\n",
    "        def sigmoid(x):\n",
    "              return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        \n",
    "        def linear_activation_forward(A_prev,W,b,activation):\n",
    "\n",
    "            if activation == \"sigmoid\":\n",
    "                Z = np.dot(W,A_prev) + b\n",
    "                A = sigmoid(Z)\n",
    "            elif activation == \"relu\":\n",
    "                Z = np.dot(W,A_prev) + b\n",
    "                A = relu(Z)\n",
    "            activation_cache = Z\n",
    "            return A,activation_cache\n",
    "                \n",
    "        \n",
    "        A = X\n",
    "        caches = []\n",
    "        L = self.number_of_layers\n",
    "        \n",
    "        for l in range(1,self.number_of_layers):\n",
    "            \n",
    "            A_prev = A\n",
    "            W,b = self.parameters[\"W\" + str(l)],self.parameters[\"b\"+str(l)]\n",
    "            linear_cache = (A_prev,W,b)\n",
    "            A,activation_cache = linear_activation_forward(A_prev=A_prev,\n",
    "                                          W=W,\n",
    "                                          b=b,\n",
    "                                          activation=\"relu\")\n",
    "            cache = (linear_cache,activation_cache)\n",
    "            caches.append(cache)\n",
    "        \n",
    "        W,b=self.parameters[\"W\"+ str(L)],self.parameters[\"b\" + str(L)]\n",
    "        linear_cache = (A,W,b)\n",
    "        A_last_layer,activation_cache = linear_activation_forward(A_prev=A,\n",
    "                                                 W=W,\n",
    "                                                 b=b,\n",
    "                                                 activation=\"sigmoid\")\n",
    "        \n",
    "        cache = (linear_cache,activation_cache)\n",
    "        caches.append(cache)\n",
    "\n",
    "        return A_last_layer,caches\n",
    "            \n",
    "   \n",
    "    \n",
    "    def __backward_propogation(self,A_last_layer,y,caches):\n",
    "\n",
    "        def linear_activation_backward(dA,cache,activation):\n",
    "             linear_cache,activation_cache = cache\n",
    "\n",
    "             if activation == \"sigmoid\":\n",
    "                 s = 1 / (1 + np.exp(-activation_cache))\n",
    "                 dZ = dA * s * (1-s)\n",
    "             elif activation == \"relu\":\n",
    "                 dZ = np.multiply(dA,np.int64(activation_cache > 0))\n",
    "\n",
    "\n",
    "              # \"\"\"linear backward\"\"\"\n",
    "             A_prev, W, b = linear_cache\n",
    "             m = A_prev.shape[1]\n",
    "\n",
    "             dW = np.dot(dZ,A_prev.T) / m \n",
    "             db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "             dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "             return dA_prev, dW, db\n",
    "              \n",
    "        \n",
    "        grads = {}\n",
    "        L = self.number_of_layers\n",
    "        y = y.reshape(A_last_layer.shape)\n",
    "\n",
    "        dA_last_layer = - (np.divide(y, A_last_layer) - np.divide(1 - y, 1 - A_last_layer));\n",
    "        dA_prev, dW, db = linear_activation_backward(dA_last_layer,caches[L - 1],\"sigmoid\")        \n",
    "        grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = dA_prev, dW, db;\n",
    "        \n",
    "        for l in reversed(range(L-1)):\n",
    "            dA = dA_prev\n",
    "            dA_prev, dW, db = linear_activation_backward(dA,caches[l],\"relu\")\n",
    "            grads[\"dA\" + str(l)] = dA_prev\n",
    "            grads[\"dW\" + str(l + 1)] = dW\n",
    "            grads[\"db\" + str(l + 1)] = db\n",
    "            \n",
    "        grads[\"dA1\"]=grads['dA2']\n",
    "        del(grads['dA2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def __update_parameters(self,learning_rate,grads):\n",
    "       \n",
    "        for l in range(1,self.number_of_layers):\n",
    "            self.parameters[\"W\" + str(l + 1)] = self.parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "            self.parameters[\"b\" + str(l + 1)] = self.parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "    \n",
    "    def __cost(self,A_last_layer,y):\n",
    "        m = y.shape[1]\n",
    "        cost = (-1 / m) * np.sum(np.multiply(y, np.log(A_last_layer)) + np.multiply(1 - y, np.log(1 - A_last_layer)))\n",
    "\n",
    "        self.cost = np.squeeze(cost)        \n",
    "\n",
    "    def fit(self,X,y,learning_rate=0.001,num_iter=1000,print_cost=False):\n",
    "\n",
    "        np.random.seed(1)\n",
    "        self.__initialize_paramters()\n",
    "\n",
    "        for i in range(0,num_iter):\n",
    "\n",
    "            # forward propa=ogation\n",
    "            last_layer_output,caches = self.__forward_propogation(X)\n",
    "            \n",
    "            #calculate cost value\n",
    "            self.__cost(last_layer_output,y)\n",
    "\n",
    "            #backward propagation\n",
    "            grads = self.__backward_propogation(A_last_layer=last_layer_output,\n",
    "                                                y=y,\n",
    "                                                caches=caches) \n",
    "\n",
    "            #update paramters\n",
    "            self.__update_parameters(learning_rate=learning_rate,\n",
    "                                     grads=grads)\n",
    "\n",
    "            if print_cost and i%100 == 0:\n",
    "                print(\"Cost after iteration {}: {}\".format(i, np.squeeze(self.cost)))\n",
    "\n",
    "                \n",
    "    def predict(self,image):\n",
    "        A_last_layer, _ = self.__forward_propogation(image)\n",
    "        print(A_last_layer)\n",
    "        predictions = (A_last_layer > 0.5).astype(int)  # Assuming binary classification\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e2903",
   "metadata": {},
   "source": [
    "# Regularization Term added for Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "199e2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BPNN:\n",
    "    def __init__(self, layer_dims):\n",
    "        self.layer_dims = layer_dims\n",
    "        self.parameters = {}\n",
    "        self.cost = 0\n",
    "        self.number_of_layers = len(self.layer_dims) - 1\n",
    "\n",
    "    def __initialize_parameters(self):\n",
    "        np.random.seed(1)\n",
    "        for l in range(1, self.number_of_layers + 1):\n",
    "            self.parameters[\"W\" + str(l)] = np.random.randn(self.layer_dims[l], self.layer_dims[l - 1]) * 0.01\n",
    "            self.parameters[\"b\" + str(l)] = np.zeros(shape=(self.layer_dims[l], 1))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def linear_activation_forward(self, A_prev, W, b, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            Z = np.dot(W, A_prev) + b\n",
    "            A = self.sigmoid(Z)\n",
    "        elif activation == \"relu\":\n",
    "            Z = np.dot(W, A_prev) + b\n",
    "            A = self.relu(Z)\n",
    "        activation_cache = Z\n",
    "        return A, activation_cache\n",
    "\n",
    "    def __forward_propagation(self, X):\n",
    "        A = X\n",
    "        caches = []\n",
    "        L = self.number_of_layers\n",
    "\n",
    "        for l in range(1, L):\n",
    "            A_prev = A\n",
    "            W, b = self.parameters[\"W\" + str(l)], self.parameters[\"b\" + str(l)]\n",
    "            linear_cache = (A_prev, W, b)\n",
    "            A, activation_cache = self.linear_activation_forward(A_prev, W, b, activation=\"relu\")\n",
    "            cache = (linear_cache, activation_cache)\n",
    "            caches.append(cache)\n",
    "\n",
    "        W, b = self.parameters[\"W\" + str(L)], self.parameters[\"b\" + str(L)]\n",
    "        linear_cache = (A, W, b)\n",
    "        A_last_layer, activation_cache = self.linear_activation_forward(A, W, b, activation=\"sigmoid\")\n",
    "\n",
    "        cache = (linear_cache, activation_cache)\n",
    "        caches.append(cache)\n",
    "\n",
    "        return A_last_layer, caches\n",
    "\n",
    "    def linear_activation_backward(self, dA, cache, activation):\n",
    "        linear_cache, activation_cache = cache\n",
    "\n",
    "        if activation == \"sigmoid\":\n",
    "            s = self.sigmoid(activation_cache)\n",
    "            dZ = dA * s * (1 - s)\n",
    "        elif activation == \"relu\":\n",
    "            dZ = np.multiply(dA, np.int64(activation_cache > 0))\n",
    "\n",
    "        A_prev, W, b = linear_cache\n",
    "        m = A_prev.shape[1]\n",
    "\n",
    "        dW = np.dot(dZ, A_prev.T) / m\n",
    "        db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "        dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "        return dA_prev, dW, db\n",
    "\n",
    "    def __backward_propagation(self, A_last_layer, y, caches, lambd):\n",
    "        grads = {}\n",
    "        L = self.number_of_layers\n",
    "        y = y.reshape(A_last_layer.shape)\n",
    "\n",
    "        dA_last_layer = - (np.divide(y, A_last_layer) - np.divide(1 - y, 1 - A_last_layer))\n",
    "        dA_prev, dW, db = self.linear_activation_backward(dA_last_layer, caches[L - 1], \"sigmoid\")\n",
    "        \n",
    "        # Add L2 regularization term to gradient\n",
    "        dW += (lambd / A_last_layer.shape[1]) * self.parameters[\"W\" + str(L)]\n",
    "\n",
    "        grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = dA_prev, dW, db\n",
    "\n",
    "        for l in reversed(range(L - 1)):\n",
    "            dA = dA_prev\n",
    "            dA_prev, dW, db = self.linear_activation_backward(dA, caches[l], \"relu\")\n",
    "            \n",
    "            # Add L2 regularization term to gradient\n",
    "            dW += (lambd / A_last_layer.shape[1]) * self.parameters[\"W\" + str(l + 1)]\n",
    "\n",
    "            grads[\"dA\" + str(l)] = dA_prev\n",
    "            grads[\"dW\" + str(l + 1)] = dW\n",
    "            grads[\"db\" + str(l + 1)] = db\n",
    "\n",
    "        grads[\"dA1\"] = grads['dA2']\n",
    "        del grads['dA2']\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def __update_parameters(self, learning_rate, grads):\n",
    "        for l in range(1, self.number_of_layers):\n",
    "            self.parameters[\"W\" + str(l + 1)] -= learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "            self.parameters[\"b\" + str(l + 1)] -= learning_rate * grads[\"db\" + str(l + 1)]\n",
    "\n",
    "    def __cost(self, A_last_layer, y, lambd):\n",
    "        m = y.shape[1]\n",
    "        cross_entropy_cost = (-1 / m) * np.sum(np.multiply(y, np.log(A_last_layer)) + np.multiply(1 - y, np.log(1 - A_last_layer)))\n",
    "        \n",
    "        # Regularization term\n",
    "        L2_regularization_cost = 0\n",
    "        for l in range(1, self.number_of_layers + 1):\n",
    "            L2_regularization_cost += np.sum(np.square(self.parameters[\"W\" + str(l)]))\n",
    "        \n",
    "        cost = cross_entropy_cost + (lambd / (2 * m)) * L2_regularization_cost\n",
    "        self.cost = np.squeeze(cost)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.001, num_iter=1000, print_cost=False, lambd=0.0):\n",
    "        np.random.seed(1)\n",
    "        self.__initialize_parameters()\n",
    "\n",
    "        for i in range(num_iter):\n",
    "            last_layer_output, caches = self.__forward_propagation(X)\n",
    "            self.__cost(last_layer_output, y, lambd)\n",
    "            grads = self.__backward_propagation(A_last_layer=last_layer_output,\n",
    "                                                y=y,\n",
    "                                                caches=caches,\n",
    "                                                lambd=lambd)\n",
    "            self.__update_parameters(learning_rate=learning_rate, grads=grads)\n",
    "\n",
    "            if print_cost and i % 100 == 0:\n",
    "                print(\"Cost after iteration {}: {}\".format(i, np.squeeze(self.cost)))\n",
    "                # print(grads['dA4'])\n",
    "                # print(grads['dW4'])\n",
    "                # print(grads['db4'])\n",
    "\n",
    "    def predict(self, image):\n",
    "        A_last_layer, _ = self.__forward_propagation(image)\n",
    "        predictions = A_last_layer\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac99defb",
   "metadata": {},
   "source": [
    "# Momentum based Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19cf129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN:\n",
    "    def __init__(self, layer_dims, beta=0.9,param=param):\n",
    "        self.layer_dims = layer_dims\n",
    "        self.parameters = param\n",
    "        self.cost = 0\n",
    "        self.number_of_layers = len(self.layer_dims) - 1\n",
    "        self.beta = beta\n",
    "        self.v = {} \n",
    "\n",
    "\n",
    "    def __initialize_paramters(self):\n",
    "        np.random.seed(1)\n",
    "        for l in range(1,self.number_of_layers + 1):\n",
    "            self.parameters[\"W\"+str(l)] = np.random.randn(self.layer_dims[l],self.layer_dims[l-1]) * 0.01\n",
    "            self.parameters[\"b\"+str(l)] = np.zeros(shape=(self.layer_dims[l],1))\n",
    "            \n",
    "    def __forward_propogation(self,X):\n",
    "\n",
    "        def relu(x):\n",
    "            return np.maximum(0,x)\n",
    "        def sigmoid(x):\n",
    "              return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        \n",
    "        def linear_activation_forward(A_prev,W,b,activation):\n",
    "\n",
    "            if activation == \"sigmoid\":\n",
    "                Z = np.dot(W,A_prev) + b\n",
    "                A = sigmoid(Z)\n",
    "            elif activation == \"relu\":\n",
    "                Z = np.dot(W,A_prev) + b\n",
    "                A = relu(Z)\n",
    "            activation_cache = Z\n",
    "            return A,activation_cache\n",
    "                \n",
    "        \n",
    "        A = X\n",
    "        caches = []\n",
    "        L = self.number_of_layers\n",
    "        \n",
    "        for l in range(1,self.number_of_layers):\n",
    "            \n",
    "            A_prev = A\n",
    "            W,b = self.parameters[\"W\" + str(l)],self.parameters[\"b\"+str(l)]\n",
    "            linear_cache = (A_prev,W,b)\n",
    "            A,activation_cache = linear_activation_forward(A_prev=A_prev,\n",
    "                                          W=W,\n",
    "                                          b=b,\n",
    "                                          activation=\"relu\")\n",
    "            cache = (linear_cache,activation_cache)\n",
    "            caches.append(cache)\n",
    "        \n",
    "        W,b=self.parameters[\"W\"+ str(L)],self.parameters[\"b\" + str(L)]\n",
    "        linear_cache = (A,W,b)\n",
    "        A_last_layer,activation_cache = linear_activation_forward(A_prev=A,\n",
    "                                                 W=W,\n",
    "                                                 b=b,\n",
    "                                                 activation=\"sigmoid\")\n",
    "        \n",
    "        cache = (linear_cache,activation_cache)\n",
    "        caches.append(cache)\n",
    "\n",
    "        return A_last_layer,caches\n",
    "            \n",
    "   \n",
    "    \n",
    "    def __backward_propogation(self,A_last_layer,y,caches):\n",
    "\n",
    "        def linear_activation_backward(dA,cache,activation):\n",
    "             linear_cache,activation_cache = cache\n",
    "\n",
    "             if activation == \"sigmoid\":\n",
    "                 s = 1 / (1 + np.exp(-activation_cache))\n",
    "                 dZ = dA * s * (1-s)\n",
    "             elif activation == \"relu\":\n",
    "                 dZ = np.multiply(dA,np.int64(activation_cache > 0))\n",
    "\n",
    "\n",
    "              # \"\"\"linear backward\"\"\"\n",
    "             A_prev, W, b = linear_cache\n",
    "             m = A_prev.shape[1]\n",
    "\n",
    "             dW = np.dot(dZ,A_prev.T) / m \n",
    "             db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "             dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "             return dA_prev, dW, db\n",
    "        \n",
    "              \n",
    "        \n",
    "        grads = {}\n",
    "        L = self.number_of_layers\n",
    "        y = y.reshape(A_last_layer.shape)\n",
    "\n",
    "        dA_last_layer = - (np.divide(y, A_last_layer) - np.divide(1 - y, 1 - A_last_layer));\n",
    "        dA_prev, dW, db = linear_activation_backward(dA_last_layer,caches[L - 1],\"sigmoid\")        \n",
    "        grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = dA_prev, dW, db;\n",
    "        \n",
    "        max_grad_norm = 1.0  # Set the maximum gradient norm\n",
    "        for l in reversed(range(L - 1)):\n",
    "            dA = dA_prev\n",
    "            dA_prev, dW, db = linear_activation_backward(dA, caches[l], \"relu\")\n",
    "\n",
    "            # Apply gradient clipping\n",
    "\n",
    "            grads[\"dA\" + str(l)] = dA_prev\n",
    "            grads[\"dW\" + str(l + 1)] = dW\n",
    "            grads[\"db\" + str(l + 1)] = db\n",
    "            \n",
    "        grads[\"dA1\"]=grads['dA2']\n",
    "        del(grads['dA2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def __update_parameters(self, learning_rate, grads):\n",
    "        for l in range(1, self.number_of_layers):\n",
    "            # Update the velocity using momentum\n",
    "            self.v[\"dW\" + str(l + 1)] = self.beta * self.v.get(\"dW\" + str(l + 1), 0) + (1 - self.beta) * grads[\"dW\" + str(l + 1)]\n",
    "            self.v[\"db\" + str(l + 1)] = self.beta * self.v.get(\"db\" + str(l + 1), 0) + (1 - self.beta) * grads[\"db\" + str(l + 1)]\n",
    "\n",
    "            # Update parameters using momentum\n",
    "            self.parameters[\"W\" + str(l + 1)] = self.parameters[\"W\" + str(l + 1)] - learning_rate * self.v[\"dW\" + str(l + 1)]\n",
    "            self.parameters[\"b\" + str(l + 1)] = self.parameters[\"b\" + str(l + 1)] - learning_rate * self.v[\"db\" + str(l + 1)]\n",
    "    \n",
    "    def __cost(self,A_last_layer,y):\n",
    "        m = y.shape[1]\n",
    "        cost = (-1 / m) * np.sum(np.multiply(y, np.log(A_last_layer)) + np.multiply(1 - y, np.log(1 - A_last_layer)))\n",
    "\n",
    "        self.cost = np.squeeze(cost)        \n",
    "\n",
    "    def fit(self,X,y,learning_rate=0.001,num_iter=1000,print_cost=False):\n",
    "\n",
    "        # np.random.seed(1)\n",
    "        # self.__initialize_paramters()\n",
    "\n",
    "        for i in range(0,num_iter):\n",
    "            \n",
    "\n",
    "            # forward propa=ogation\n",
    "            last_layer_output,caches = self.__forward_propogation(X)\n",
    "            \n",
    "            #calculate cost value\n",
    "            self.__cost(last_layer_output,y)\n",
    "\n",
    "            #backward propagation\n",
    "            grads = self.__backward_propogation(A_last_layer=last_layer_output,\n",
    "                                                y=y,\n",
    "                                                caches=caches) \n",
    "\n",
    "            #update paramters\n",
    "            self.__update_parameters(learning_rate=learning_rate,\n",
    "                                     grads=grads)\n",
    "            if self.cost < 0.05:\n",
    "                print(\"Cost after iteration {}: {}\".format(i, np.squeeze(self.cost)))\n",
    "                break\n",
    "\n",
    "            if print_cost and i%100 == 0:\n",
    "                print(\"Cost after iteration {}: {}\".format(i, np.squeeze(self.cost)))\n",
    "\n",
    "                \n",
    "    def predict(self,image):\n",
    "        A_last_layer, _ = self.__forward_propogation(image)\n",
    "        print(A_last_layer)\n",
    "        predictions = (A_last_layer > 0.5).astype(int)  # Assuming binary classification\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f40b30",
   "metadata": {},
   "source": [
    "# Nestrov-Accelerated Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba66650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN:\n",
    "    def __init__(self,layer_dims):\n",
    "        self.layer_dims = layer_dims\n",
    "        self.parameters = {}\n",
    "        self.cost = 0\n",
    "        self.number_of_layers = len(self.layer_dims) - 1\n",
    "\n",
    "\n",
    "    def __initialize_paramters(self):\n",
    "        np.random.seed(1)\n",
    "        for l in range(1,self.number_of_layers + 1):\n",
    "            self.parameters[\"W\"+str(l)] = np.random.randn(self.layer_dims[l],self.layer_dims[l-1]) * 0.01\n",
    "            self.parameters[\"b\"+str(l)] = np.zeros(shape=(self.layer_dims[l],1))\n",
    "            \n",
    "    def __forward_propogation(self,X):\n",
    "\n",
    "        def relu(x):\n",
    "            return np.maximum(0,x)\n",
    "        def sigmoid(x):\n",
    "              return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        \n",
    "        def linear_activation_forward(A_prev,W,b,activation):\n",
    "\n",
    "            if activation == \"sigmoid\":\n",
    "                Z = np.dot(W,A_prev) + b\n",
    "                A = sigmoid(Z)\n",
    "            elif activation == \"relu\":\n",
    "                Z = np.dot(W,A_prev) + b\n",
    "                A = relu(Z)\n",
    "            activation_cache = Z\n",
    "            return A,activation_cache\n",
    "                \n",
    "        \n",
    "        A = X\n",
    "        caches = []\n",
    "        L = self.number_of_layers\n",
    "        \n",
    "        for l in range(1,self.number_of_layers):\n",
    "            \n",
    "            A_prev = A\n",
    "            W,b = self.parameters[\"W\" + str(l)],self.parameters[\"b\"+str(l)]\n",
    "            linear_cache = (A_prev,W,b)\n",
    "            A,activation_cache = linear_activation_forward(A_prev=A_prev,\n",
    "                                          W=W,\n",
    "                                          b=b,\n",
    "                                          activation=\"relu\")\n",
    "            cache = (linear_cache,activation_cache)\n",
    "            caches.append(cache)\n",
    "        \n",
    "        W,b=self.parameters[\"W\"+ str(L)],self.parameters[\"b\" + str(L)]\n",
    "        linear_cache = (A,W,b)\n",
    "        A_last_layer,activation_cache = linear_activation_forward(A_prev=A,\n",
    "                                                 W=W,\n",
    "                                                 b=b,\n",
    "                                                 activation=\"sigmoid\")\n",
    "        \n",
    "        cache = (linear_cache,activation_cache)\n",
    "        caches.append(cache)\n",
    "\n",
    "        return A_last_layer,caches\n",
    "            \n",
    "   \n",
    "    \n",
    "    def __backward_propogation(self,A_last_layer,y,caches):\n",
    "\n",
    "        def linear_activation_backward(dA,cache,activation):\n",
    "             linear_cache,activation_cache = cache\n",
    "\n",
    "             if activation == \"sigmoid\":\n",
    "                 s = 1 / (1 + np.exp(-activation_cache))\n",
    "                 dZ = dA * s * (1-s)\n",
    "             elif activation == \"relu\":\n",
    "                 dZ = np.multiply(dA,np.int64(activation_cache > 0))\n",
    "\n",
    "\n",
    "              # \"\"\"linear backward\"\"\"\n",
    "             A_prev, W, b = linear_cache\n",
    "             m = A_prev.shape[1]\n",
    "\n",
    "             dW = np.dot(dZ,A_prev.T) / m \n",
    "             db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "             dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "             return dA_prev, dW, db\n",
    "              \n",
    "        \n",
    "        grads = {}\n",
    "        L = self.number_of_layers\n",
    "        y = y.reshape(A_last_layer.shape)\n",
    "\n",
    "        dA_last_layer = - (np.divide(y, A_last_layer) - np.divide(1 - y, 1 - A_last_layer));\n",
    "        dA_prev, dW, db = linear_activation_backward(dA_last_layer,caches[L - 1],\"sigmoid\")        \n",
    "        grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = dA_prev, dW, db;\n",
    "        \n",
    "        for l in reversed(range(L-1)):\n",
    "            dA = dA_prev\n",
    "            dA_prev, dW, db = linear_activation_backward(dA,caches[l],\"relu\")\n",
    "            grads[\"dA\" + str(l)] = dA_prev\n",
    "            grads[\"dW\" + str(l + 1)] = dW\n",
    "            grads[\"db\" + str(l + 1)] = db\n",
    "            \n",
    "        grads[\"dA1\"]=grads['dA2']\n",
    "        del(grads['dA2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def __update_parameters(self, learning_rate, grads, momentum=0.9):\n",
    "        for l in range(1, self.number_of_layers):\n",
    "            # Nesterov Update for weights\n",
    "            self.parameters[\"W\" + str(l + 1)] -= learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "            self.parameters[\"W\" + str(l + 1)] -= momentum * learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "\n",
    "            # Nesterov Update for biases\n",
    "            self.parameters[\"b\" + str(l + 1)] -= learning_rate * grads[\"db\" + str(l + 1)]\n",
    "            self.parameters[\"b\" + str(l + 1)] -= momentum * learning_rate * grads[\"db\" + str(l + 1)]\n",
    "    \n",
    "    def __cost(self,A_last_layer,y):\n",
    "        m = y.shape[1]\n",
    "        cost = (-1 / m) * np.sum(np.multiply(y, np.log(A_last_layer)) + np.multiply(1 - y, np.log(1 - A_last_layer)))\n",
    "\n",
    "        self.cost = np.squeeze(cost)        \n",
    "\n",
    "    def fit(self,X,y,learning_rate=0.001,num_iter=1000,print_cost=False):\n",
    "\n",
    "        np.random.seed(1)\n",
    "        self.__initialize_paramters()\n",
    "\n",
    "        for i in range(0,num_iter):\n",
    "\n",
    "            # forward propa=ogation\n",
    "            last_layer_output,caches = self.__forward_propogation(X)\n",
    "            \n",
    "            #calculate cost value\n",
    "            self.__cost(last_layer_output,y)\n",
    "\n",
    "            #backward propagation\n",
    "            grads = self.__backward_propogation(A_last_layer=last_layer_output,\n",
    "                                                y=y,\n",
    "                                                caches=caches) \n",
    "\n",
    "            #update paramters\n",
    "            self.__update_parameters(learning_rate=learning_rate,\n",
    "                                     grads=grads)\n",
    "\n",
    "            if print_cost and i%100 == 0:\n",
    "                print(\"Cost after iteration {}: {}\".format(i, np.squeeze(self.cost)))\n",
    "\n",
    "                \n",
    "    def predict(self,image):\n",
    "        A_last_layer, _ = self.__forward_propogation(image)\n",
    "        print(A_last_layer)\n",
    "        predictions = (A_last_layer > 0.5).astype(int)  # Assuming binary classification\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18adb12e-cdfc-4881-93d2-eb3c0e6b8e26",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48f7a292-4f39-49bd-bd07-8c2a05d59d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [12288, 20, 7, 5, 1] #  4-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31603b05-1cae-43b1-9ea2-38681bf2b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BPNN(layer_dims=layers_dims,param=param)\n",
    "model2.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    learning_rate=1,\n",
    "    num_iter=4000,\n",
    "    print_cost=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf69696b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.01624345, -0.00611756, -0.00528172, ..., -0.00527214,\n",
       "         -0.0038034 ,  0.00949412],\n",
       "        [ 0.01009231,  0.00229889, -0.00664099, ...,  0.00689859,\n",
       "         -0.00488322,  0.0020761 ],\n",
       "        [-0.0035634 , -0.00195481,  0.00636803, ...,  0.00822751,\n",
       "         -0.00104425, -0.00657957],\n",
       "        ...,\n",
       "        [ 0.00174745, -0.00130162,  0.01835827, ..., -0.00922606,\n",
       "         -0.00824792, -0.00153355],\n",
       "        [-0.0003495 , -0.00417018, -0.0085517 , ...,  0.02247331,\n",
       "         -0.00533637, -0.00029554],\n",
       "        [-0.01434299, -0.01110641,  0.00726317, ...,  0.0219863 ,\n",
       "          0.01538192,  0.00746604]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan]]),\n",
       " 'b2': array([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]]),\n",
       " 'W3': array([[nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan]]),\n",
       " 'b3': array([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]]),\n",
       " 'W4': array([[nan, nan, nan, nan, nan]]),\n",
       " 'b4': array([[nan]])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da88945f-5b3f-437a-b883-c2967b72da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09944556 0.07306573 0.08331717 0.96979689 0.94978505 0.30234134\n",
      "  0.17158672 0.99401294 0.99982353 0.57346074 1.         0.11663578\n",
      "  0.99863366 0.07119308 0.99963283 0.91605813 0.18946687 0.57346074\n",
      "  0.17416726 0.10930437 0.99999198 0.07119308 0.20718208 0.99721679\n",
      "  0.99999971 0.99642978 0.57346074 0.08923851 0.35408354 0.10495517\n",
      "  0.52766949 0.23787352 0.67268459 0.25642145 0.08523603 0.1552926\n",
      "  0.08744746 0.99171711 0.11481777 0.12563206 0.21949959 0.99991514\n",
      "  0.57346074 0.15749461 0.57346074 0.57346074 0.11049745 0.57346074\n",
      "  0.99996255 0.10544757]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a0ba8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = list(pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2814071",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test =list( y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9ea7796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.00%\n"
     ]
    }
   ],
   "source": [
    "correctly_classified = 0\n",
    "for count in range(np.size(y_test)):\n",
    "    if y_test[count] == pred[count]:\n",
    "        correctly_classified += 1\n",
    "\n",
    "accuracy_percentage = (correctly_classified / np.size(y_test)) * 100\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_percentage))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
